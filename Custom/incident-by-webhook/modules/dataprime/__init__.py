# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: service/com/coralogixapis/dataprime/v1/query_service.proto, service/com/coralogixapis/dataprime/v1/request.proto, service/com/coralogixapis/dataprime/v1/response.proto
# plugin: python-betterproto
# This file has been @generated

from dataclasses import dataclass
from datetime import datetime
from typing import (
    TYPE_CHECKING,
    AsyncIterator,
    Dict,
    List,
    Optional,
)

import betterproto
import grpclib
from betterproto.grpc.grpclib_server import ServiceBase


if TYPE_CHECKING:
    import grpclib.server
    from betterproto.grpc.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline


class MetadataTier(betterproto.Enum):
    """tier on which query runs, default: TIER_FREQUENT_SEARCH"""

    TIER_UNSPECIFIED = 0
    TIER_ARCHIVE = 1
    TIER_FREQUENT_SEARCH = 2


class MetadataQuerySyntax(betterproto.Enum):
    """syntax of the query, default: QUERY_SYNTAX_DATAPRIME"""

    QUERY_SYNTAX_UNSPECIFIED = 0
    QUERY_SYNTAX_LUCENE = 1
    QUERY_SYNTAX_DATAPRIME = 2


@dataclass(eq=False, repr=False)
class QueryRequest(betterproto.Message):
    """dataprime text query request"""

    query: Optional[str] = betterproto.message_field(1, wraps=betterproto.TYPE_STRING)
    """query for which you seek results"""

    metadata: Optional["Metadata"] = betterproto.message_field(
        2, optional=True, group="_metadata"
    )
    """configuration of query execution"""


@dataclass(eq=False, repr=False)
class Metadata(betterproto.Message):
    """configuration of query execution"""

    start_date: Optional[datetime] = betterproto.message_field(
        1, optional=True, group="_start_date"
    )
    """
    beginning of the time range for the query, default: end - 15 min or current
    time - 15 min if end is not defined
    """

    end_date: Optional[datetime] = betterproto.message_field(
        2, optional=True, group="_end_date"
    )
    """
    end of the time range for the query, default: start + 15 min or current
    time if start is not defined
    """

    default_source: Optional[Optional[str]] = betterproto.message_field(
        3, wraps=betterproto.TYPE_STRING, optional=True, group="_default_source"
    )
    """
    default value for source to be used when source is omitted in a query
    """

    tier: Optional["MetadataTier"] = betterproto.enum_field(
        4, optional=True, group="_tier"
    )
    """tier on which query runs"""

    syntax: Optional["MetadataQuerySyntax"] = betterproto.enum_field(
        5, optional=True, group="_syntax"
    )
    """which syntax query is written in"""

    limit: Optional[int] = betterproto.int32_field(6, optional=True, group="_limit")
    """
    limit number of results, default: 2000; max for TIER_FREQUENT_SEARCH:
    12000;  max for TIER_ARCHIVE: 50000
    """

    strict_fields_validation: Optional[bool] = betterproto.bool_field(
        7, optional=True, group="_strict_fields_validation"
    )
    """
    prohibit using unknown fields, ones which were not detected in the ingested
    data, default = false
    """


@dataclass(eq=False, repr=False)
class QueryResponse(betterproto.Message):
    """dataprime response for text query"""

    error: Optional["DataprimeError"] = betterproto.message_field(1)
    result: Optional["DataprimeResult"] = betterproto.message_field(2)
    warning: Optional["DataprimeWarning"] = betterproto.message_field(3)
    query_id: Optional["QueryId"] = betterproto.message_field(4)


@dataclass(eq=False, repr=False)
class DataprimeError(betterproto.Message):
    """wrapper for dataprime error"""

    message: Optional[str] = betterproto.message_field(1)
    code: Optional["DataprimeErrorCode"] = betterproto.message_field(2)


@dataclass(eq=False, repr=False)
class DataprimeResult(betterproto.Message):
    """batch of results"""

    results: List["DataprimeResults"] = betterproto.message_field(1)


@dataclass(eq=False, repr=False)
class DataprimeWarning(betterproto.Message):
    """warning message"""

    compile_warning: Optional["CompileWarning"] = betterproto.message_field(1)
    time_range_warning: Optional["TimeRangeWarning"] = betterproto.message_field(2)
    number_of_results_limit_warning: Optional["NumberOfResultsLimitWarning"] = betterproto.message_field(3)
    bytes_scanned_limit_warning: Optional["BytesScannedLimitWarning"] = betterproto.message_field(4)
    deprecation_warning: Optional["DeprecationWarning"] = betterproto.message_field(5)
    blocks_limit_warning: Optional["BlocksLimitWarning"] = betterproto.message_field(6)
    aggregation_buckets_limit_warning: Optional["AggregationBucketsLimitWarning"] = betterproto.message_field(7)
    archive_warning: Optional["ArchiveWarning"] = betterproto.message_field(8)
    scroll_timeout_warning: Optional["ScrollTimeoutWarning"] = betterproto.message_field(9)
    field_count_limit_warning: Optional["FieldCountLimitWarning"] = betterproto.message_field(10)
    shuffle_file_size_limit_reached_warning: Optional["ShuffleFileSizeLimitReachedWarning"] = betterproto.message_field(11)



@dataclass(eq=False, repr=False)
class CompileWarning(betterproto.Message):
    """warning from Dataprime compilation"""

    warning_message: str = betterproto.string_field(1)


@dataclass(eq=False, repr=False)
class TimeRangeWarning(betterproto.Message):
    """warning from applying time range to query"""

    warning_message: str = betterproto.string_field(1)
    start_date: Optional[datetime] = betterproto.message_field(
        2, optional=True, group="_start_date"
    )
    end_date: Optional[datetime] = betterproto.message_field(
        3, optional=True, group="_end_date"
    )


@dataclass(eq=False, repr=False)
class NumberOfResultsLimitWarning(betterproto.Message):
    """warning from applying limit on number of results"""

    number_of_results_limit: int = betterproto.int32_field(1)


@dataclass(eq=False, repr=False)
class BytesScannedLimitWarning(betterproto.Message):
    """warning for reaching bytes scanned limit"""

    pass


@dataclass(eq=False, repr=False)
class AggregationBucketsLimitWarning(betterproto.Message):
    """warning for reaching aggregation buckets limit"""

    aggregation_buckets_limit: int = betterproto.int32_field(1)


@dataclass(eq=False, repr=False)
class DeprecationWarning(betterproto.Message):
    """warning about deprecated elements"""

    warning_message: str = betterproto.string_field(1)


@dataclass(eq=False, repr=False)
class BlocksLimitWarning(betterproto.Message):
    """Warning for when query has reached maximum number of parquet blocks"""

    pass


@dataclass(eq=False, repr=False)
class DataprimeResult(betterproto.Message):
    """batch of results"""

    results: List["DataprimeResults"] = betterproto.message_field(2)


@dataclass(eq=False, repr=False)
class DataprimeResults(betterproto.Message):
    """wrapper for dataprime results"""

    metadata: List["DataprimeResultsKeyValue"] = betterproto.message_field(1)
    labels: List["DataprimeResultsKeyValue"] = betterproto.message_field(2)
    user_data: str = betterproto.string_field(3)


@dataclass(eq=False, repr=False)
class DataprimeResultsKeyValue(betterproto.Message):
    key: str = betterproto.string_field(1)
    value: str = betterproto.string_field(2)


@dataclass(eq=False, repr=False)
class DataprimeError(betterproto.Message):
    """wrapper for dataprime error"""

    message: Optional[str] = betterproto.message_field(1, wraps=betterproto.TYPE_STRING)
    code: Optional["DataprimeErrorCode"] = betterproto.message_field(
        2, optional=True, group="_code"
    )


@dataclass(eq=False, repr=False)
class DataprimeErrorRateLimitReached(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class DataprimeErrorCode(betterproto.Message):
    rate_limit_reached: "DataprimeErrorRateLimitReached" = betterproto.message_field(
        1, group="message"
    )


@dataclass(eq=False, repr=False)
class SerializedDataprime(betterproto.Message):
    """wrapper for byte AST representation"""

    data: bytes = betterproto.bytes_field(1)


@dataclass(eq=False, repr=False)
class QueryId(betterproto.Message):
    """
    internal identifier of the query. Can be used to simplify investigation of
    issues
    """

    query_id: str = betterproto.string_field(1)


@dataclass(eq=False, repr=False)
class ArchiveWarning(betterproto.Message):
    """wrapper for archive related warnings"""

    no_metastore_data: Optional["ArchiveWarningNoMetastoreData"] = betterproto.message_field(1)
    bucket_access_denied: Optional["ArchiveWarningBucketAccessDenied"] = betterproto.message_field(2)
    bucket_read_failed: Optional["ArchiveWarningBucketReadFailed"] = betterproto.message_field(3)
    missing_data: Optional["ArchiveWarningMissingData"] = betterproto.message_field(4)



@dataclass(eq=False, repr=False)
class ArchiveWarningNoMetastoreData(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class ArchiveWarningBucketAccessDenied(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class ArchiveWarningBucketReadFailed(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class ArchiveWarningMissingData(betterproto.Message):
    pass


@dataclass(eq=False, repr=False)
class ScrollTimeoutWarning(betterproto.Message):
    """warning for when OpenSearch scroll timeout is reached"""

    pass


@dataclass(eq=False, repr=False)
class FieldCountLimitWarning(betterproto.Message):
    """
    warning for when result contain entries where number of fields is truncated
    """

    pass


@dataclass(eq=False, repr=False)
class ShuffleFileSizeLimitReachedWarning(betterproto.Message):
    """
    warning for when shuffle file size limit is reached - e.g. during a join
    with a large right side
    """

    pass


class DataprimeQueryServiceStub(betterproto.ServiceStub):
    async def query(
        self,
        query_request: "QueryRequest",
        *,
        timeout: Optional[float] = None,
        deadline: Optional["Deadline"] = None,
        metadata: Optional["MetadataLike"] = None
    ) -> AsyncIterator["QueryResponse"]:
        async for response in self._unary_stream(
            "/com.coralogixapis.dataprime.v1.DataprimeQueryService/Query",
            query_request,
            QueryResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        ):
            yield response


class DataprimeQueryServiceBase(ServiceBase):

    async def query(
        self, query_request: "QueryRequest"
    ) -> AsyncIterator["QueryResponse"]:
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)
        yield QueryResponse()

    async def __rpc_query(
        self, stream: "grpclib.server.Stream[QueryRequest, QueryResponse]"
    ) -> None:
        request = await stream.recv_message()
        await self._call_rpc_handler_server_stream(
            self.query,
            stream,
            request,
        )

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/com.coralogixapis.dataprime.v1.DataprimeQueryService/Query": grpclib.const.Handler(
                self.__rpc_query,
                grpclib.const.Cardinality.UNARY_STREAM,
                QueryRequest,
                QueryResponse,
            ),
        }
